{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Object detection with OpenCV.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOn2KKpWuvwGsCFSQwgWYTf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"7EuiniDLOgPz","colab_type":"text"},"source":["# **Object Detection with OpenCV**\n","![대체 텍스트](https://www.pyimagesearch.com/wp-content/uploads/2017/09/example06_result.jpg)\n","\n","we’ll discuss how to apply object detection using deep learning and OpenCV.\n","\n","When it comes to deep learning-based object detection there are three primary object detection methods that you’ll likely encounter:\n","\n","\n","\n","1.   Faster R-CNNs (Girshick et al., 2015) - 7 FPS.\n","2.   You Only Look Once (YOLO) (Redmon and Farhadi, 2015) - 40-90 FPS.\n","3.   Single Shot Detectors (SSDs) (Liu et al., 2015) - 22-46 FPS.\n","\n","object detection networks we normally use an existing network architecture\n","\n","\n","\n","1.   VGG\n","2.   ResNet\n","3.   MobileNets\n","\n","these network architectures(VGG, ResNet) can be very large in the order of 200-500MB. could be unsuitable for resource constrained devices.\n","“MobileNets\", they are designed for resource constrained devices such as your smartphone.  \n","\n","\n","\n","**MobileNet architecture and the Single Shot Detector (SSD) framework, we arrive at a fast, efficient deep learning-based method to object detection.**\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"AtPxxLIUfBBf","colab_type":"text"},"source":["# Data Load of image, video and model"]},{"cell_type":"code","metadata":{"id":"6UK52wz3_mms","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":580},"executionInfo":{"status":"ok","timestamp":1596606003164,"user_tz":-540,"elapsed":8307,"user":{"displayName":"유은정","photoUrl":"","userId":"11867406313502038872"}},"outputId":"16a63cc8-4190-448f-c373-1339558a2563"},"source":["%%shell\n","mkdir objectDetection; cd objectDetection\n","mkdir model; cd model\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Model/MobileNetSSD_deploy.prototxt\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Model/MobileNetSSD_deploy.caffemodel\n","cd ..; mkdir images; cd images\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Images/example_01.jpg\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Images/example_02.jpg\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Images/example_03.jpg\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Images/example_04.jpg\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Images/example_05.jpg\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Images/example_06.jpg"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   170  100   170    0     0    939      0 --:--:-- --:--:-- --:--:--   934\n","\r100 29353  100 29353    0     0  79980      0 --:--:-- --:--:-- --:--:-- 79980\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   172  100   172    0     0    988      0 --:--:-- --:--:-- --:--:--   988\n","100 22.0M  100 22.0M    0     0  17.7M      0  0:00:01  0:00:01 --:--:-- 41.2M\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   157  100   157    0     0    912      0 --:--:-- --:--:-- --:--:--   912\n","100 48070  100 48070    0     0   104k      0 --:--:-- --:--:-- --:--:-- 2091k\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   157  100   157    0     0    892      0 --:--:-- --:--:-- --:--:--   892\n","100  6391  100  6391    0     0  19544      0 --:--:-- --:--:-- --:--:-- 19544\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   157  100   157    0     0    963      0 --:--:-- --:--:-- --:--:--   963\n","100  102k  100  102k    0     0   262k      0 --:--:-- --:--:-- --:--:--  262k\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   157    0   157    0     0    902      0 --:--:-- --:--:-- --:--:--   902\n","100 39578  100 39578    0     0   112k      0 --:--:-- --:--:-- --:--:-- 2973k\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   157  100   157    0     0    826      0 --:--:-- --:--:-- --:--:--   826\n","100  120k  100  120k    0     0   288k      0 --:--:-- --:--:-- --:--:--  288k\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   157    0   157    0     0    857      0 --:--:-- --:--:-- --:--:--   857\n","100 69090  100 69090    0     0   164k      0 --:--:-- --:--:-- --:--:--  164k\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"r-Q_Z1GhcFie","colab_type":"code","colab":{}},"source":["# import the necessary packages\n","import numpy as np\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4MyA5bozhiT8","colab_type":"code","colab":{}},"source":["# Root directory of the project\n","ROOT_DIR = os.path.abspath(\"./objectDetection/\")\n","# Directory to save logs and trained model\n","MODEL_DIR = os.path.join(ROOT_DIR, \"model\")\n","# Directory of images/video to run detection on\n","IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")\n","\n","prototxtPath = os.path.sep.join([MODEL_DIR, \"MobileNetSSD_deploy.prototxt\"])  \n","weightsPath = os.path.sep.join([MODEL_DIR, \"MobileNetSSD_deploy.caffemodel\"]) \n","objectNet = cv2.dnn.readNetFromCaffe(prototxtPath, weightsPath)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CpqhOyCsmAmo","colab_type":"code","colab":{}},"source":["# initialize the list of class labels MobileNet SSD was trained to\n","# detect, then generate a set of bounding box colors for each class\n","CLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n","\t          \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\"sofa\", \"train\", \"tvmonitor\"]\n","COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))\n","conf_threshold = 0.25     "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"l-_jz9qC5bCQ","colab_type":"text"},"source":["# **1**.Detection model demo by picture"]},{"cell_type":"code","metadata":{"id":"KHv3M3l8q9XF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1596606133282,"user_tz":-540,"elapsed":778,"user":{"displayName":"유은정","photoUrl":"","userId":"11867406313502038872"}},"outputId":"8faf85ec-ad26-43f1-b954-7fecda14eafa"},"source":["# load the input image\n","image_list = []\n","for file in os.listdir(IMAGE_DIR):\n","  file_path = os.path.join(IMAGE_DIR, file)\n","  if(os.path.isfile(file_path)): \n","    image = cv2.imread(file_path)\n","    print(\"The image of {} : {}\".format(file, image.shape))\n","    image_list.append(image)   "],"execution_count":null,"outputs":[{"output_type":"stream","text":["The image of example_05.jpg : (375, 500, 3)\n","The image of example_04.jpg : (400, 300, 3)\n","The image of example_01.jpg : (600, 800, 3)\n","The image of example_06.jpg : (530, 600, 3)\n","The image of example_03.jpg : (450, 600, 3)\n","The image of example_02.jpg : (240, 360, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yEQElEd-EgQ5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596606144301,"user_tz":-540,"elapsed":1365,"user":{"displayName":"유은정","photoUrl":"","userId":"11867406313502038872"}},"outputId":"6410134f-6ff8-402d-d9bc-68f72c8ddccb"},"source":["# construct an input blob for the image\n","blob_list = []\n","for image in image_list:\n","  blob = cv2.dnn.blobFromImage(image, 0.007843, (300, 300), 127.5)   \n","  blob_list.append(blob)\n","\n","print(\"The Blob : {}\".format(np.array(blob_list).shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The Blob : (6, 1, 3, 300, 300)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vQ5z5J8OrIQa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1596606303049,"user_tz":-540,"elapsed":2011,"user":{"displayName":"유은정","photoUrl":"","userId":"11867406313502038872"}},"outputId":"ba1160d0-1cba-4a2a-a5af-6e8f72612394"},"source":["# pass the blob through the network and obtain the detections and predictions\n","detections_list = []\n","for blob in blob_list:\n","  objectNet.setInput(blob)\n","  detections = objectNet.forward()    \n","  detections_list.append(detections)\n","print(\"The Detections: {}\".format(np.array(detections_list).shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The Detections: (6, 1, 1, 100, 7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VR-4S_i_rdkL","colab_type":"code","colab":{}},"source":["# loop over the detections\n","for i, detections in enumerate(detections_list):\n","\tfor j in np.arange(0, detections.shape[2]):\n","\t\t(high, width) = image_list[i].shape[:2]\n","\t\tconfidence = detections[0, 0, j, 2]\n","\n","\t\tif confidence > conf_threshold:\n","\t\t\tidx = int(detections[0, 0, j, 1])\n","\t \n","\t\t\tbox = detections[0, 0, j, 3:7] * np.array([width, high, width, high])           \n","\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n","\n","\t\t\tlabel = \"{}: {:.2f}%\".format(CLASSES[idx], confidence * 100)\n","\t\t\tcv2.rectangle(image_list[i], (startX, startY), (endX, endY), COLORS[idx], 2)\n","\t\t\ty = startY - 15 if startY - 15 > 15 else startY + 15\n","\t\t\tcv2.putText(image_list[i], label, (startX, y),cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yrrtX7NXrg1R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1XJxLEEI4gZbJ0vgnF6Z4vU054-c5N7iw"},"executionInfo":{"status":"ok","timestamp":1596606468818,"user_tz":-540,"elapsed":3601,"user":{"displayName":"유은정","photoUrl":"","userId":"11867406313502038872"}},"outputId":"744d8490-d61b-4d7d-bf3c-26d259b46045"},"source":["# show the output image\n","for image in image_list:\n","  cv2_imshow(image)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"kOdWGNm5e5RK","colab_type":"text"},"source":["# **2**.Detection model demo by video"]},{"cell_type":"code","metadata":{"id":"0rJEsakbm9zd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1596606582840,"user_tz":-540,"elapsed":2589,"user":{"displayName":"유은정","photoUrl":"","userId":"11867406313502038872"}},"outputId":"51d94afe-e758-4f77-a0bb-516b0c9fa601"},"source":["%%shell\n","cd objectDetection\n","mkdir videos; cd videos\n","curl -LJO https://github.com/phoebe81/DetectionWithOpenCV/raw/master/Videos/pedestrian.mp4  > pedestrian.mp4\n","cd videos\n","mkdir save"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   157  100   157    0     0    590      0 --:--:-- --:--:-- --:--:--   590\n","100 2013k  100 2013k    0     0  2662k      0 --:--:-- --:--:-- --:--:-- 7772k\n","/bin/bash: line 3: cd: videos: No such file or directory\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"0pr5FxODmIQq","colab_type":"code","colab":{}},"source":["VIDEO_DIR = os.path.join(ROOT_DIR, \"videos\")\n","VIDEO_SAVE_DIR = os.path.join(VIDEO_DIR, \"save\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O7FikcHOmEpA","colab_type":"text"},"source":["## Processing Funtions"]},{"cell_type":"code","metadata":{"id":"qD2LymJ9oBMl","colab_type":"code","colab":{}},"source":["import base64, logging\n","import numpy as np\n","from PIL import Image\n","from io import BytesIO\n","\n","def data_uri_to_img(uri):\n","  try:\n","    image = base64.b64decode(uri.split(',')[1], validate=True)\n","    image = Image.open(BytesIO(image))\n","    image = np.array(image, dtype=np.uint8); \n","    return image\n","  except Exception as e:\n","    logging.exception(e);print('\\n')\n","    return None\n","\n","def video_to_data_url(filename):\n","    ext = filename.split('.')[-1]\n","    prefix = 'data:video/{};base64,'.format(ext)\n","    with open(filename, 'rb') as f:\n","        vidoe = f.read()\n","    return prefix + base64.b64encode(vidoe).decode()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cnEH-dIrq1nG","colab_type":"code","colab":{}},"source":["def detect_and_predict_object(frame):\n","  height, width = frame.shape[:2]\n","  \n","  blob = cv2.dnn.blobFromImage(frame, 0.007843, (300, 300), 127.5)  \n","  objectNet.setInput(blob)\n","  detections = objectNet.forward()  \n","\n","  for i in np.arange(0, detections.shape[2]):\n","    confidence = detections[0, 0, i, 2]\n","\n","    if confidence > conf_threshold:           \n","      idx = int(detections[0, 0, i, 1])\n","      box = detections[0, 0, i, 3:7]* np.array([width, height, width, height])    \n","      (startX, startY, endX, endY) = box.astype(\"int\")\n","\n","      label = \"{}: {:.2f}%\".format(CLASSES[idx], confidence * 100)\n","      cv2.rectangle(frame, (startX, startY), (endX, endY), COLORS[idx], 2)\n","      y = startY - 15 if startY - 15 > 15 else startY + 15\n","      cv2.putText(frame, label, (startX, y),cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lqQhfJmao_1X","colab_type":"text"},"source":["\n","## Videdo Capture\n","Using a webcam to capture images for processing on the runtime.\n","Source: https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb#scrollTo=2viqYx97hPMi\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"dn9KvfbFe9Pd","colab_type":"code","colab":{}},"source":["from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","\n","# playing webcam or video with javascript\n","def take_photo(filename='photo.jpg', quality=0.8):\n","  js = Javascript('''     \n","    async function takePhoto(filename, quality) {\n","                  \n","      const div = document.createElement('div');\n","      document.body.appendChild(div);\n","\n","      const exit = document.createElement('button');\n","      exit.textContent = 'Exit';\n","      div.appendChild(exit);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","           \n","      if('photo.jpg' == filename){\n","        const stream = await navigator.mediaDevices.getUserMedia({video: true}); \n","        video.srcObject = stream;   \n","      }else{\n","        video.src = filename;\n","        video.type=\"video/mp4\"\n","      }\n","      await video.play();  \n","      div.appendChild(video);       \n","                   \n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","      \n","      let jsLog = function(abc) {\n","        document.querySelector(\"#output-area\").appendChild(document.createTextNode(`${abc}... `));\n","      }\n","\n","      // when Exit button is clicked.   \n","      var isOpened = true; \n","      var exitPromise = new Promise((resolve) => {exit.onclick = resolve});   \n","      exitPromise.then(()=>{isOpened = false; stream.getVideoTracks()[0].stop();});\n","      \n","      //when end of video\n","      var endPromise = new Promise((resolve) => {video.onended = resolve});   \n","      endPromise.then(()=>{isOpened = false; video.stop();});\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","\n","      for (let i = 0; isOpened; i++) {\n","        canvas.getContext(\"2d\").clearRect(0, 0, canvas.width, canvas.height);\n","        canvas.getContext('2d').drawImage(video, 0, 0);\n","        img = canvas.toDataURL('image/jpeg', quality);\n","\n","        // jsLog(i + \"sending\");\n","        // Call a python function and send this image\n","        google.colab.kernel.invokeFunction('notebook.run_objectDetection', [img], {});\n","        // jsLog(i + \"SENT\");\n","\n","        // wait for X miliseconds second, before next capture\n","        await new Promise(resolve => setTimeout(resolve, 250));        \n","      }       \n","      div.remove();      \n","    }    \n","    ''')  \n","  # make the provided HTML, part of the cell\n","  display(js)\n","  #call the takePhoto() JavaScript function\n","  eval_js('takePhoto({},{})'.format(\"'\"+filename+\"'\", quality)) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WIwCv18al39e","colab_type":"code","colab":{}},"source":["from google.colab import output\n","frame_count = 0\n","writer = None\n","\n","# InvokeFunction\n","def run_objectDetection(uri): \n","  global frame_count, writer\n","\n","  image = data_uri_to_img(uri)   \n","  if writer is None:\t\t\n","      fourcc = cv2.VideoWriter_fourcc(*'DIVX')  \n","      writer = cv2.VideoWriter(outVideo, fourcc, 2, (image.shape[1], image.shape[0]), True)\n","  try:    \n","    detect_and_predict_object(image)    \n","\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n","    frame_count+=1    \n","    name = '{0}.jpg'.format(frame_count)\n","    name = os.path.join(VIDEO_SAVE_DIR, name)\n","    cv2.imwrite(name, image)\n","\n","    if writer is not None:\n","      writer.write(image)\n","  except Exception as e:\n","    logging.exception(e)\n","    print('\\n')\n","\n","# register this function, so JS code could call this\n","output.register_callback('notebook.run_objectDetection', run_objectDetection)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8ZA3SSYavo-6","colab_type":"text"},"source":["## Apply Detection model"]},{"cell_type":"code","metadata":{"id":"gF8FRm2XjVfL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1596607460005,"user_tz":-540,"elapsed":2343,"user":{"displayName":"유은정","photoUrl":"","userId":"11867406313502038872"}},"outputId":"7b650d70-22d3-43fe-d4aa-ec6b02e94df5"},"source":[" %%shell\n"," cd objectDetection\n"," rm ./videos/save/* \n"," rm ./videos/out.avi"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"KlN_UP7uo1Sp","colab_type":"code","colab":{}},"source":["inVideo = os.path.join(VIDEO_DIR, \"pedestrian.mp4\")\n","outVideo= os.path.join(VIDEO_DIR, \"out.avi\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2_NuWXqNvn6w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1596607430095,"user_tz":-540,"elapsed":16585,"user":{"displayName":"유은정","photoUrl":"","userId":"11867406313502038872"}},"outputId":"6b8c61f8-03ff-47d1-ebd9-ea9c822488a6"},"source":["frame_count = 0\n","data_url = video_to_data_url(inVideo)\n","try: \n","  # put the JS code in cell and run it\n","  take_photo()  \n","  if writer is not None:\n","    writer.release()   \n","except Exception as e:\n","  logging.exception(e)\n","  print('\\n')\n","\n","writer = None"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["     \n","    async function takePhoto(filename, quality) {\n","                  \n","      const div = document.createElement('div');\n","      document.body.appendChild(div);\n","\n","      const exit = document.createElement('button');\n","      exit.textContent = 'Exit';\n","      div.appendChild(exit);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","           \n","      if('photo.jpg' == filename){\n","        const stream = await navigator.mediaDevices.getUserMedia({video: true}); \n","        video.srcObject = stream;   \n","      }else{\n","        video.src = filename;\n","        video.type=\"video/mp4\"\n","      }\n","      await video.play();  \n","      div.appendChild(video);       \n","                   \n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","      \n","      let jsLog = function(abc) {\n","        document.querySelector(\"#output-area\").appendChild(document.createTextNode(`${abc}... `));\n","      }\n","\n","      // when Exit button is clicked.   \n","      var isOpened = true; \n","      var exitPromise = new Promise((resolve) => {exit.onclick = resolve});   \n","      exitPromise.then(()=>{isOpened = false; stream.getVideoTracks()[0].stop();});\n","      \n","      //when end of video\n","      var endPromise = new Promise((resolve) => {video.onended = resolve});   \n","      endPromise.then(()=>{isOpened = false; video.stop();});\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","\n","      for (let i = 0; isOpened; i++) {\n","        canvas.getContext(\"2d\").clearRect(0, 0, canvas.width, canvas.height);\n","        canvas.getContext('2d').drawImage(video, 0, 0);\n","        img = canvas.toDataURL('image/jpeg', quality);\n","\n","        // jsLog(i + \"sending\");\n","        // Call a python function and send this image\n","        google.colab.kernel.invokeFunction('notebook.run_objectDetection', [img], {});\n","        // jsLog(i + \"SENT\");\n","\n","        // wait for X miliseconds second, before next capture\n","        await new Promise(resolve => setTimeout(resolve, 250));        \n","      }       \n","      div.remove();      \n","    }    \n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"muigCBexq5h4","colab_type":"text"},"source":["## Downlod  to our local machine"]},{"cell_type":"code","metadata":{"id":"J7sog1ibBFpQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1596607438608,"user_tz":-540,"elapsed":1397,"user":{"displayName":"유은정","photoUrl":"","userId":"11867406313502038872"}},"outputId":"140598c4-6551-46de-dbbb-10107c431be7"},"source":["from google.colab import files\n","files.download(outVideo)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_b3b99534-4953-40d5-9db9-9f1b12bc2e7a\", \"out.avi\", 267822)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]}]}