{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Face detection with OpenCV.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNC4N/WLB/hKkKw6saeoyJI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"NrpnfDf6-mow","colab_type":"text"},"source":["# **Face detection with OpenCV**\n","![대체 텍스트](https://pyimagesearch.com/wp-content/uploads/2018/02/deep_learning_face_detection_opencv.gif)"]},{"cell_type":"markdown","metadata":{"id":"2Xt5W8J7ab7Y","colab_type":"text"},"source":["\n","\n","1.   OpenCV’s deep learning face detector is based on **the Single Shot Detector (SSD)** framework with a **ResNet** base network. \n","2.   The network is defined and trained using the [Caffe Deep Learning framework](https://caffe.berkeleyvision.org/)\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"DpngwycqYaCk","colab_type":"text"},"source":["# Data Load of image, video and model\n","\n","\n","Download the pre-trained face detection model, consisting of two files:\n","\n","- The network definition (face_deploy.prototxt)\n","- The learned weights (res10_300x300_ssd_iter_140000.caffemodel) \n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"u1ijI1cqKnFT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"status":"ok","timestamp":1596545082170,"user_tz":-540,"elapsed":3417,"user":{"displayName":"유은정","photoUrl":"","userId":"11867406313502038872"}},"outputId":"46908eed-02c6-47d5-e1bd-bda360626960"},"source":["%%shell\n","mkdir faceDection\n","cd faceDection\n","\n","mkdir model\n","curl http://blogattach.naver.net/ec79f04b506766d0f7187d4c7195e69031609f11/20200314_59_blogfile/handuelly_1584190461913_BL2c0O_pbtxt/opencv_face_detector.pbtxt > ./model/face_deploy.prototxt\n","curl http://blogattach.naver.net/91048d3c241a1bad8a6500310fec95e84d18e748/20200314_96_blogfile/handuelly_1584190468004_Q7ui27_pb/opencv_face_detector_uint8.pb > ./model/face_deploy.caffemodel\n","\n","mkdir images\n","curl https://jnswire.s3.amazonaws.com/jns-media/e0/3b/1498256/Names_10.jpeg  > ./images/example_01.jpg\n","curl https://i.ytimg.com/vi/igkKs9O5wPg/maxresdefault.jpg  > ./images/example_02.jpg\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100   318  100   318    0     0    876      0 --:--:-- --:--:-- --:--:--   876\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100   318  100   318    0     0   1204      0 --:--:-- --:--:-- --:--:--  1200\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  253k  100  253k    0     0   457k      0 --:--:-- --:--:-- --:--:--  457k\n","  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  158k  100  158k    0     0  6104k      0 --:--:-- --:--:-- --:--:-- 6104k\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"lB1UTW-RQolk","colab_type":"code","colab":{}},"source":["# import the necessary packages\n","import numpy as np\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3LpINvOdJLnu","colab_type":"code","colab":{}},"source":["# Root directory of the project\n","ROOT_DIR = os.path.abspath(\"./faceDection/\")\n","# Directory to save logs and trained model\n","MODEL_DIR = os.path.join(ROOT_DIR, \"model\")\n","# Directory of images/video to run detection on\n","IMAGE_DIR = os.path.join(ROOT_DIR, \"images\")\n","\n","prototxtPath = os.path.sep.join([MODEL_DIR, \"face_deploy.prototxt\"])  \n","weightsPath = os.path.sep.join([MODEL_DIR, \"face_deploy.caffemodel\"]) \n","faceNet = cv2.dnn.readNetFromCaffe(prototxtPath, weightsPath)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TvlfZVzATY5m","colab_type":"code","colab":{}},"source":["conf_threshold = 0.25"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H3XswjjwSQrw","colab_type":"text"},"source":["# **1**.Detection model demo by picture"]},{"cell_type":"code","metadata":{"id":"-JoK3gizSGi1","colab_type":"code","colab":{}},"source":["# load the input image\n","image_list = []\n","detections_list = [] \n","for file in os.listdir(IMAGE_DIR):\n","  file_path = os.path.join(IMAGE_DIR, file)\n","  if(os.path.isfile(file_path)): \n","    image = cv2.imread(file_path)\n","    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0,(300, 300), (104.0, 177.0, 123.0)) \n","    faceNet.setInput(blob)\n","    detections = faceNet.forward()\n","    image_list.append(image)\n","    detections_list.append(detections)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cyhey5cOSyme","colab_type":"code","colab":{}},"source":["# loop over the detections\n","for i, detections in enumerate(detections_list):\n","\tfor j in range(0, detections.shape[2]):\n","\t\t# extract the confidence (i.e., probability) associated with the prediction\n","\t\tconfidence = detections[0, 0, j, 2]\n","\n","\t\t# filter out weak detections by ensuring the `confidence` is  greater than the minimum confidence\n","\t\tif confidence > conf_threshold:\n","\t\t\t# compute the (x, y)-coordinates of the bounding box for the\n","\t\t\t# object\n","\t\t\tbox = detections[0, 0, j, 3:7] * np.array([image_list[i].shape[1], image_list[i].shape[0], image_list[i].shape[1], image_list[i].shape[0]])    \n","\t\t\t(startX, startY, endX, endY) = box.astype(\"int\")\n","\t\n","\t\t\t# draw the bounding box of the face along with the associated\n","\t\t\t# probability\n","\t\t\ttext = \"{:.2f}%\".format(confidence * 100)\n","\t\t\ty = startY - 10 if startY - 10 > 10 else startY + 10\n","\t\t\tcv2.rectangle(image_list[i], (startX, startY), (endX, endY), (0, 0, 255), 2)\n","\t\t\tcv2.putText(image_list[i], text, (startX, y),cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EvT507utTAmX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1ly2AiRWUaCmMlZ-qYqVcy3LUst1tr_6D"},"executionInfo":{"status":"ok","timestamp":1596163750174,"user_tz":-540,"elapsed":12780,"user":{"displayName":"유은정","photoUrl":"","userId":"11867406313502038872"}},"outputId":"793c11e8-6f66-4c38-952b-ed5d22c29316"},"source":["# show the output image\n","for image in image_list:\n","  cv2_imshow(image)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"uLZHx_5KTyz2","colab_type":"text"},"source":["# **2**.Detection model demo by video"]},{"cell_type":"code","metadata":{"id":"TlkQzLHJTyBL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":318},"executionInfo":{"status":"ok","timestamp":1596545369886,"user_tz":-540,"elapsed":3563,"user":{"displayName":"유은정","photoUrl":"","userId":"11867406313502038872"}},"outputId":"cba7df0e-9996-4b72-935b-f119588934f0"},"source":["%%shell\n","cd faceDection\n","mkdir videos\n","# wget https://github.com/Tony607/blog_statics/releases/download/v1.0/trailer1.mp4 -P ./videos\n","cd videos\n","mkdir save"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-08-04 12:49:27--  https://github.com/Tony607/blog_statics/releases/download/v1.0/trailer1.mp4\n","Resolving github.com (github.com)... 192.30.255.112\n","Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/104032162/9a38bc98-3059-11e8-92b6-d7fcc470e802?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200804%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200804T124927Z&X-Amz-Expires=300&X-Amz-Signature=c801683337eb59ac2bdce359f5bdfd53bf924df922f89feb9e143059e49446cd&X-Amz-SignedHeaders=host&actor_id=0&repo_id=104032162&response-content-disposition=attachment%3B%20filename%3Dtrailer1.mp4&response-content-type=application%2Foctet-stream [following]\n","--2020-08-04 12:49:27--  https://github-production-release-asset-2e65be.s3.amazonaws.com/104032162/9a38bc98-3059-11e8-92b6-d7fcc470e802?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200804%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200804T124927Z&X-Amz-Expires=300&X-Amz-Signature=c801683337eb59ac2bdce359f5bdfd53bf924df922f89feb9e143059e49446cd&X-Amz-SignedHeaders=host&actor_id=0&repo_id=104032162&response-content-disposition=attachment%3B%20filename%3Dtrailer1.mp4&response-content-type=application%2Foctet-stream\n","Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.80.224\n","Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.80.224|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 20300902 (19M) [application/octet-stream]\n","Saving to: ‘./videos/trailer1.mp4’\n","\n","trailer1.mp4        100%[===================>]  19.36M  21.7MB/s    in 0.9s    \n","\n","2020-08-04 12:49:28 (21.7 MB/s) - ‘./videos/trailer1.mp4’ saved [20300902/20300902]\n","\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"FrdSNyXDT_54","colab_type":"code","colab":{}},"source":["VIDEO_DIR = os.path.join(ROOT_DIR, \"videos\")\n","VIDEO_SAVE_DIR = os.path.join(VIDEO_DIR, \"save\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g2L6VSybUHt7","colab_type":"text"},"source":["## Processing Funtions"]},{"cell_type":"code","metadata":{"id":"XJgZgJqxUfee","colab_type":"code","colab":{}},"source":["import base64, logging\n","import numpy as np\n","from PIL import Image\n","from io import BytesIO\n","\n","def data_uri_to_img(uri):\n","  try:\n","    image = base64.b64decode(uri.split(',')[1], validate=True)\n","    # make the binary image, a PIL image\n","    image = Image.open(BytesIO(image))\n","    # convert to numpy array\n","    image = np.array(image, dtype=np.uint8); \n","    return image\n","  except Exception as e:\n","    logging.exception(e);print('\\n')\n","    return None\n","\n","def video_to_data_url(filename):\n","    ext = filename.split('.')[-1]\n","    prefix = 'data:video/{};base64,'.format(ext)\n","    with open(filename, 'rb') as f:\n","        vidoe = f.read()\n","    return prefix + base64.b64encode(vidoe).decode()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SeCQzKu1UG7J","colab_type":"code","colab":{}},"source":["def detect_and_predict_face(frame):\n","  height, width = frame.shape[:2]\n","\n","  blob = cv2.dnn.blobFromImage(frame, 1.0,(300, 300), (104.0, 177.0, 123.0)) \n","  faceNet.setInput(blob)\n","  detections = faceNet.forward()       \n","\n","  for i in np.arange(0, detections.shape[2]):\n","    confidence = detections[0, 0, i, 2]\n","    \n","    if confidence > conf_threshold:\n","      box = detections[0, 0, i, 3:7]* np.array([width, height, width, height])   \n","      (startX, startY, endX, endY) = box.astype(\"int\")\n","\t\n","      text = \"{:.2f}%\".format(confidence * 100)\n","      y = startY - 10 if startY - 10 > 10 else startY + 10\n","      cv2.rectangle(frame, (startX, startY), (endX, endY), (0, 0, 255), 2)\n","      cv2.putText(frame, text, (startX, y),cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DscFdLmgU14p","colab_type":"text"},"source":["\n","## Videdo Capture\n","Using a webcam to capture images for processing on the runtime.\n","Source: https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb#scrollTo=2viqYx97hPMi"]},{"cell_type":"code","metadata":{"id":"SugDRjaBUy2G","colab_type":"code","colab":{}},"source":["from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","\n","# playing webcam or video with javascript\n","def take_photo(filename='photo.jpg', quality=0.8):\n","  js = Javascript('''     \n","    async function takePhoto(filename, quality) {\n","                  \n","      const div = document.createElement('div');\n","      document.body.appendChild(div);\n","\n","      const exit = document.createElement('button');\n","      exit.textContent = 'Exit';\n","      div.appendChild(exit);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","           \n","      if('photo.jpg' == filename){\n","        const stream = await navigator.mediaDevices.getUserMedia({video: true}); \n","        video.srcObject = stream;   \n","      }else{\n","        video.src = filename;\n","        video.type=\"video/mp4\"\n","      }\n","      await video.play();  \n","      div.appendChild(video);       \n","                   \n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","      \n","      let jsLog = function(abc) {\n","        document.querySelector(\"#output-area\").appendChild(document.createTextNode(`${abc}... `));\n","      }\n","\n","      // when Exit button is clicked.   \n","      var isOpened = true; \n","      var exitPromise = new Promise((resolve) => {exit.onclick = resolve});   \n","      exitPromise.then(()=>{isOpened = false; stream.getVideoTracks()[0].stop();});\n","      \n","      //when end of video\n","      var endPromise = new Promise((resolve) => {video.onended = resolve});   \n","      endPromise.then(()=>{isOpened = false; video.stop();});\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","\n","      for (let i = 0; isOpened; i++) {\n","        canvas.getContext(\"2d\").clearRect(0, 0, canvas.width, canvas.height);\n","        canvas.getContext('2d').drawImage(video, 0, 0);\n","        img = canvas.toDataURL('image/jpeg', quality);\n","\n","        // jsLog(i + \"sending\");\n","        // Call a python function and send this image\n","        google.colab.kernel.invokeFunction('notebook.run_faceDetection', [img], {});\n","        // jsLog(i + \"SENT\");\n","\n","        // wait for X miliseconds second, before next capture\n","        await new Promise(resolve => setTimeout(resolve, 250));        \n","      }       \n","      div.remove();      \n","    }    \n","    ''')  \n","  # make the provided HTML, part of the cell\n","  display(js)\n","  #call the takePhoto() JavaScript function\n","  eval_js('takePhoto({},{})'.format(\"'\"+filename+\"'\", quality)) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"785gt7j5U8OZ","colab_type":"code","colab":{}},"source":["from google.colab import output\n","frame_count = 0\n","writer = None\n","\n","# InvokeFunction\n","# takes the numpy image and runs detection, then shows the results by visualizing\n","def run_faceDetection(uri): \n","  global frame_count, writer\n","\n","  image = data_uri_to_img(uri)     \n","  if writer is None:\t\t\n","      fourcc = cv2.VideoWriter_fourcc(*'DIVX')  \n","      writer = cv2.VideoWriter(outVideo, fourcc, 2, (image.shape[1], image.shape[0]), True)\n","  try:        \n","    detect_and_predict_face(image)\n","\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) \n","    frame_count+=1    \n","    name = '{0}.jpg'.format(frame_count)\n","    name = os.path.join(VIDEO_SAVE_DIR, name)\n","    cv2.imwrite(name, image)\n","\n","    if writer is not None:\n","      writer.write(image)\n","  except Exception as e:\n","    logging.exception(e)\n","    print('\\n')\n","\n","# register this function, so JS code could call this\n","output.register_callback('notebook.run_faceDetection', run_faceDetection)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y1jg3FIFVUwy","colab_type":"text"},"source":["## Apply Detection model"]},{"cell_type":"code","metadata":{"id":"VRWp-vUTjhVU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1596546150059,"user_tz":-540,"elapsed":2442,"user":{"displayName":"유은정","photoUrl":"","userId":"11867406313502038872"}},"outputId":"0054a4b7-1f23-40f9-c221-3b8f1f1fe5d9"},"source":[" %%shell\n"," cd faceDection\n"," rm ./videos/save/* \n"," rm ./videos/out.avi"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":[""]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"8Xy3mC1yVUeG","colab_type":"code","colab":{}},"source":["inVideo = os.path.join(VIDEO_DIR, \"BTS.mp4\")\n","outVideo= os.path.join(VIDEO_DIR, \"out.avi\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KGESu6j9RfZf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1596545635666,"user_tz":-540,"elapsed":13633,"user":{"displayName":"유은정","photoUrl":"","userId":"11867406313502038872"}},"outputId":"77c0b508-dcd3-411d-91e5-5dfaa3729be8"},"source":["data_url = video_to_data_url(inVideo)\n","try: \n","  # put the JS code in cell and run it\n","  take_photo()  \n","  if writer is not None:\n","    writer.release()\n","except Exception as e:\n","  logging.exception(e)\n","  print('\\n')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["     \n","    async function takePhoto(filename, quality) {\n","                  \n","      const div = document.createElement('div');\n","      document.body.appendChild(div);\n","\n","      const exit = document.createElement('button');\n","      exit.textContent = 'Exit';\n","      div.appendChild(exit);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","           \n","      if('photo.jpg' == filename){\n","        const stream = await navigator.mediaDevices.getUserMedia({video: true}); \n","        video.srcObject = stream;   \n","      }else{\n","        video.src = filename;\n","        video.type=\"video/mp4\"\n","      }\n","      await video.play();  \n","      div.appendChild(video);       \n","                   \n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","      \n","      let jsLog = function(abc) {\n","        document.querySelector(\"#output-area\").appendChild(document.createTextNode(`${abc}... `));\n","      }\n","\n","      // when Exit button is clicked.   \n","      var isOpened = true; \n","      var exitPromise = new Promise((resolve) => {exit.onclick = resolve});   \n","      exitPromise.then(()=>{isOpened = false; stream.getVideoTracks()[0].stop();});\n","      \n","      //when end of video\n","      var endPromise = new Promise((resolve) => {video.onended = resolve});   \n","      endPromise.then(()=>{isOpened = false; video.stop();});\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","\n","      for (let i = 0; isOpened; i++) {\n","        canvas.getContext(\"2d\").clearRect(0, 0, canvas.width, canvas.height);\n","        canvas.getContext('2d').drawImage(video, 0, 0);\n","        img = canvas.toDataURL('image/jpeg', quality);\n","\n","        jsLog(i + \"sending\");\n","        // Call a python function and send this image\n","        google.colab.kernel.invokeFunction('notebook.run_faceDetection', [img], {});\n","        jsLog(i + \"SENT\");\n","\n","        // wait for X miliseconds second, before next capture\n","        await new Promise(resolve => setTimeout(resolve, 250));        \n","      }       \n","      div.remove();      \n","    }    \n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"PPJh-qFpWG-y","colab_type":"text"},"source":["### Downlod  to our local machine"]},{"cell_type":"code","metadata":{"id":"m0I4KWhiWGRp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1596545643723,"user_tz":-540,"elapsed":855,"user":{"displayName":"유은정","photoUrl":"","userId":"11867406313502038872"}},"outputId":"b44b645c-580a-479e-e61d-a81a48a7953e"},"source":["from google.colab import files\n","files.download(outVideo)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_9c4d3657-f0ad-4d94-a4f3-b1f342d757b7\", \"out.avi\", 3405730)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]}]}